{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering National Home Markets\n",
    "\n",
    "You work for a large national bank, who has a large lending business devoted toward providing loans to people who want to borrow to buy homes across the United States. The bank wants to have a model which can identify how similar, at any given time, the national real estate market is to other real estate periods which have occured in the past. After all, quantifying the nature of today's real estate market to those that have occured in the past will help the bank understand its lending risk, as well as the potential for new growth.\n",
    "\n",
    "To that effect, you've decided to use the `KMeans` unsupervised learning algorithm to segment different periods in the U.S. market for national residential house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the `national-home-sales.csv` file from the Resources folder and create a DataFrame. Set the “date” column to create the DatetimeIndex. Be sure to include parameters for `parse_dates` and `infer_datetime_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV file as a Pandas DataFrame\n",
    "home_sales_df = pd.read_csv(\n",
    "  Path(\"../Resources/national-home-sales.csv\"),\n",
    "  index_col=\"date\", \n",
    "  parse_dates=True, \n",
    "  infer_datetime_format=True \n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "home_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create two lists: one to hold the list of inertia scores and another for the range of k values (from 1 to 11) to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a a list to store inertia values\n",
    "inertia = []\n",
    "\n",
    "# Create a a list to store the values of k\n",
    "k = list(range(1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a for-loop to evaluate each instance of k, define a K-means model, fit the K-means model based on the scaled DataFrame, and append the model’s inertia to the empty inertia list that you created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for-loop where each value of k is evaluated using the K-means algorithm\n",
    "# Fit the model using the spread_df DataFrame\n",
    "# Append the value of the computed inertia from the `inertia_` attribute of the KMeans model instance\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, random_state=2, n_init=10)\n",
    "    k_model.fit(home_sales_df)\n",
    "    inertia.append(k_model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the values for k and the inertia in a Dictionary called `elbow_data`. Use `elbow_data` to create a Pandas DataFrame called `df_elbow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dictionary that holds the list values for k and inertia\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "\n",
    "# Create a DataFrame using the elbow_data Dictionary\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "\n",
    "# Review the DataFrame\n",
    "df_elbow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hvPlot, plot the `df_elbow` DataFrame to visualize the elbow curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DataFrame\n",
    "df_elbow.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\"Elbow Curve\", \n",
    "    xticks=k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the following tasks for each of the two most likely values of `k`:\n",
    "\n",
    "* Define a K-means model using `k` to define the clusters, fit the model, make predictions, and add the prediction values to a copy of the scaled DataFrame and call it `spread_predictions_df`.\n",
    "\n",
    "* Plot the clusters. The x-axis should reflect home \"inventory\", and the y-axis should reflect either the \"median_sale_price\" or \"homes_sold\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with the lower value of k clusters\n",
    "# Use a random_state of 1 to generate the model\n",
    "model = KMeans(n_clusters=3, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(home_sales_df)\n",
    "\n",
    "# Make predictions\n",
    "k_lower = model.predict(home_sales_df)\n",
    "\n",
    "# Create a copy of the DataFrame and name it as spread_df_predictions\n",
    "home_sales_predictions_df = home_sales_df.copy()\n",
    "\n",
    "# Add a class column with the labels to the spread_df_predictions DataFrame\n",
    "home_sales_predictions_df['clusters_lower'] = k_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_sales_predictions_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters\n",
    "home_sales_predictions_df.hvplot.scatter(\n",
    "    x=\"inventory\",\n",
    "    y=\"homes_sold\",\n",
    "    by=\"clusters_lower\"\n",
    ").opts(yformatter=\"%.0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with the higher value of k clusters\n",
    "# Use a random_state of 1 to generate the model\n",
    "model = KMeans(n_clusters=4, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(home_sales_df)\n",
    "\n",
    "# Make predictions\n",
    "k_higher = model.predict(home_sales_df)\n",
    "\n",
    "# Add a class column with the labels to the spread_df_predictions DataFrame\n",
    "home_sales_predictions_df['clusters_higher'] = k_higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(home_sales_predictions_df, \n",
    "                    x='inventory', \n",
    "                    y='homes_sold', \n",
    "                    z='median_sale_price',\n",
    "                    color='clusters_lower')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters\n",
    "home_sales_predictions_df.hvplot.scatter(\n",
    "    x=\"inventory\",\n",
    "    y=\"homes_sold\",\n",
    "    by=\"clusters_higher\"\n",
    ").opts(yformatter=\"%.0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer the following question\n",
    "\n",
    "* Considering the plot, what’s the best number of clusters to choose, or value of k? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plots, it appears that the optimal value for k, the nubmer of clusters is probably 3. It appears to better group the monthly housing trends among different levels of inventory. However, 4 clusters is probably not wrong either as, for a certain range of inventory, it appears to identify two unique clusters according to the number of homes sold. Overall, the best differention across multiple variables though would likely be 3 clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
